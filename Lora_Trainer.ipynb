{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bea32e7",
   "metadata": {},
   "source": [
    "# ‚≠ê Lora Trainer by dmikey\n",
    "**Version 2.0** - All-in-One Edition (February 2026) | `8e79c81`\n",
    "\n",
    "This is based on the work of [Hollowstrawberry](https://github.com/hollowstrawberry/kohya-colab), [Kohya-ss](https://github.com/kohya-ss/sd-scripts) and [Linaqruf](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb). Thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af3756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612ee397",
   "metadata": {},
   "source": [
    "### ‚≠ï Disclaimer\n",
    "The purpose of this document is to research bleeding-edge technologies in the field of machine learning.  \n",
    "Please read and follow the [Google Colab guidelines](https://research.google.com/colaboratory/faq.html) and its [Terms of Service](https://research.google.com/colaboratory/tos_v3.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34ed5d",
   "metadata": {},
   "source": [
    "| |GitHub|\n",
    "|:--|:-:|\n",
    "| ‚≠ê **Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/dmikey/kohya-colab/main/assets/github.svg)](https://github.com/dmikey/kohya-colab/blob/main/Lora_Trainer.ipynb) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c608f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ## ‚≠ê LoRA Trainer - All-in-One\n",
    "#@markdown ### ‚ñ∂Ô∏è Setup\n",
    "#@markdown Your project name will be the same as the folder containing your images. Spaces aren't allowed.\n",
    "project_name = \"my_lora\" #@param {type:\"string\"}\n",
    "#@markdown The folder structure doesn't matter and is purely for comfort.\n",
    "folder_structure = \"Organize by project (MyDrive/Loras/project_name/dataset)\" #@param [\"Organize by category (MyDrive/lora_training/datasets/project_name)\", \"Organize by project (MyDrive/Loras/project_name/dataset)\"]\n",
    "#@markdown Choose your training model:\n",
    "training_model = \"Anime (animefull-final-pruned-fp16.safetensors)\" #@param [\"Anime (animefull-final-pruned-fp16.safetensors)\", \"AnyLora (AnyLoRA_noVae_fp16-pruned.ckpt)\", \"Stable Diffusion (sd-v1-5-pruned-noema-fp16.safetensors)\"]\n",
    "optional_custom_training_model_url = \"\" #@param {type:\"string\"}\n",
    "custom_model_is_based_on_sd2 = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ### ‚ñ∂Ô∏è Processing\n",
    "resolution = 512 #@param {type:\"slider\", min:512, max:1024, step:128}\n",
    "flip_aug = False #@param {type:\"boolean\"}\n",
    "shuffle_tags = True #@param {type:\"boolean\"}\n",
    "activation_tags = \"1\" #@param [0,1,2,3]\n",
    "\n",
    "#@markdown ### ‚ñ∂Ô∏è Steps\n",
    "num_repeats = 10 #@param {type:\"number\"}\n",
    "preferred_unit = \"Epochs\" #@param [\"Epochs\", \"Steps\"]\n",
    "how_many = 10 #@param {type:\"number\"}\n",
    "save_every_n_epochs = 1 #@param {type:\"number\"}\n",
    "keep_only_last_n_epochs = 10 #@param {type:\"number\"}\n",
    "train_batch_size = 2 #@param {type:\"slider\", min:1, max:8, step:1}\n",
    "\n",
    "#@markdown ### ‚ñ∂Ô∏è Learning\n",
    "unet_lr = 5e-4 #@param {type:\"number\"}\n",
    "text_encoder_lr = 1e-4 #@param {type:\"number\"}\n",
    "lr_scheduler = \"cosine_with_restarts\" #@param [\"constant\", \"cosine\", \"cosine_with_restarts\", \"constant_with_warmup\", \"linear\", \"polynomial\"]\n",
    "lr_scheduler_number = 3 #@param {type:\"number\"}\n",
    "lr_warmup_ratio = 0.05 #@param {type:\"slider\", min:0.0, max:0.5, step:0.01}\n",
    "min_snr_gamma = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ### ‚ñ∂Ô∏è Structure\n",
    "lora_type = \"LoRA\" #@param [\"LoRA\", \"LoCon\"]\n",
    "network_dim = 16 #@param {type:\"slider\", min:1, max:128, step:1}\n",
    "network_alpha = 8 #@param {type:\"slider\", min:1, max:128, step:1}\n",
    "conv_dim = 8 #@param {type:\"slider\", min:1, max:64, step:1}\n",
    "conv_alpha = 4 #@param {type:\"slider\", min:1, max:64, step:1}\n",
    "\n",
    "#@markdown ### ‚ñ∂Ô∏è Optimizer\n",
    "optimizer = \"AdamW8bit\" #@param [\"AdamW8bit\", \"Prodigy\", \"DAdaptation\", \"AdamW\", \"Lion\", \"SGDNesterov\"]\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: Install Dependencies\n",
    "# =============================================================================\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from time import time\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 1: Installing Dependencies\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Detect environment\n",
    "COLAB = 'google.colab' in str(get_ipython()) if 'get_ipython' in dir() else False\n",
    "root_dir = \"/content\" if COLAB else os.path.expanduser(\"~/Loras\")\n",
    "repo_dir = os.path.join(root_dir, \"kohya-trainer\")\n",
    "\n",
    "# Mount Google Drive if on Colab\n",
    "if COLAB and not os.path.exists('/content/drive'):\n",
    "    from google.colab import drive\n",
    "    print(\"üìÇ Connecting to Google Drive...\")\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "os.chdir(root_dir)\n",
    "\n",
    "print(\"\\nüè≠ Installing dependencies...\\n\")\n",
    "t0 = time()\n",
    "\n",
    "# Clone fresh kohya_ss\n",
    "if os.path.exists(repo_dir):\n",
    "    !rm -rf {repo_dir}\n",
    "\n",
    "!git clone --quiet https://github.com/kohya-ss/sd-scripts {repo_dir}\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "# Install system dependencies\n",
    "!apt -y update -qq\n",
    "!apt -y install aria2 -qq\n",
    "\n",
    "# Install Python packages\n",
    "print(\"Installing PyTorch and xformers...\")\n",
    "!pip install -q torch==2.1.2 torchvision==0.16.2 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q xformers==0.0.23.post1 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "print(\"Installing kohya requirements...\")\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"Installing additional packages...\")\n",
    "!pip install -q prodigyopt lion-pytorch tensorboard\n",
    "\n",
    "# Try to install compatible bitsandbytes\n",
    "print(\"Installing bitsandbytes...\")\n",
    "bitsandbytes_available = False\n",
    "\n",
    "# Detect actual CUDA version\n",
    "import torch\n",
    "cuda_version = torch.version.cuda\n",
    "print(f\"   Detected CUDA version: {cuda_version}\")\n",
    "\n",
    "# Install matching bitsandbytes version\n",
    "if cuda_version and cuda_version.startswith(\"12\"):\n",
    "    !pip install -q bitsandbytes>=0.43.0\n",
    "else:\n",
    "    !pip install -q bitsandbytes==0.41.1\n",
    "\n",
    "# Verify it actually works (import test)\n",
    "try:\n",
    "    import bitsandbytes as bnb\n",
    "    # Force a real check - the import alone doesn't catch CUDA issues\n",
    "    _ = bnb.optim.AdamW8bit\n",
    "    print(f\"‚úì bitsandbytes {bnb.__version__} installed successfully\")\n",
    "    bitsandbytes_available = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è bitsandbytes not functional: {e}\")\n",
    "    print(\"   Uninstalling broken bitsandbytes to prevent crashes...\")\n",
    "    !pip uninstall -y bitsandbytes -q\n",
    "    print(\"   Will use standard optimizers instead of 8-bit variants\")\n",
    "\n",
    "# Verify xformers installation\n",
    "try:\n",
    "    import xformers\n",
    "    print(f\"‚úì xformers {xformers.__version__} installed successfully\")\n",
    "    xformers_available = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è xformers not available - will disable in config\")\n",
    "    xformers_available = False\n",
    "\n",
    "# Setup accelerate\n",
    "from accelerate.utils import write_basic_config\n",
    "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
    "os.makedirs(os.path.dirname(accelerate_config), exist_ok=True)\n",
    "if not os.path.exists(accelerate_config):\n",
    "    write_basic_config(save_location=accelerate_config)\n",
    "\n",
    "# Environment variables\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
    "os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
    "\n",
    "t1 = time()\n",
    "print(f\"\\n‚úÖ Installation finished in {int(t1-t0)} seconds.\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: Setup Training Configuration\n",
    "# =============================================================================\n",
    "import re\n",
    "import toml\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2: Setting Up Training Configuration\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Model URL mapping\n",
    "if optional_custom_training_model_url:\n",
    "    model_url = optional_custom_training_model_url\n",
    "elif \"AnyLora\" in training_model:\n",
    "    model_url = \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16-pruned.ckpt\"\n",
    "elif \"Anime\" in training_model:\n",
    "    model_url = \"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/resolve/main/models/animefull-final-pruned-fp16.safetensors\"\n",
    "else:\n",
    "    model_url = \"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/resolve/main/models/sd-v1-5-pruned-noema-fp16.safetensors\"\n",
    "\n",
    "# Setup paths\n",
    "if \"/Loras\" in folder_structure:\n",
    "    main_dir = os.path.join(root_dir, \"drive/MyDrive/Loras\") if COLAB else root_dir\n",
    "    log_folder = os.path.join(main_dir, \"_logs\")\n",
    "    config_folder = os.path.join(main_dir, project_name)\n",
    "    images_folder = os.path.join(main_dir, project_name, \"dataset\")\n",
    "    output_folder = os.path.join(main_dir, project_name, \"output\")\n",
    "else:\n",
    "    main_dir = os.path.join(root_dir, \"drive/MyDrive/lora_training\") if COLAB else root_dir\n",
    "    images_folder = os.path.join(main_dir, \"datasets\", project_name)\n",
    "    output_folder = os.path.join(main_dir, \"output\", project_name)\n",
    "    config_folder = os.path.join(main_dir, \"config\", project_name)\n",
    "    log_folder = os.path.join(main_dir, \"log\")\n",
    "\n",
    "config_file = os.path.join(config_folder, \"training_config.toml\")\n",
    "dataset_config_file = os.path.join(config_folder, \"dataset_config.toml\")\n",
    "accelerate_config_file = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
    "\n",
    "# Create directories\n",
    "for d in [main_dir, log_folder, images_folder, output_folder, config_folder]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Validate dataset\n",
    "print(\"\\nüíø Checking dataset...\")\n",
    "project_name = project_name.strip()\n",
    "if not project_name or any(c in project_name for c in \" .()\\\"'\\\\/\"):\n",
    "    raise ValueError(\"Please choose a valid project name (no spaces or special characters).\")\n",
    "\n",
    "supported_types = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")\n",
    "if not os.path.exists(images_folder):\n",
    "    raise ValueError(f\"Dataset folder doesn't exist: {images_folder}\")\n",
    "\n",
    "files = os.listdir(images_folder)\n",
    "images = [f for f in files if f.lower().endswith(supported_types)]\n",
    "if not images:\n",
    "    raise ValueError(f\"No images found in {images_folder}\")\n",
    "\n",
    "caption_extension = \".txt\" if [f for f in files if f.lower().endswith(\".txt\")] else \"\"\n",
    "keep_tokens = int(activation_tags)\n",
    "shuffle_caption = shuffle_tags\n",
    "\n",
    "# Calculate steps\n",
    "max_train_epochs = how_many if preferred_unit == \"Epochs\" else None\n",
    "max_train_steps = how_many if preferred_unit == \"Steps\" else None\n",
    "steps_per_epoch = (len(images) * num_repeats) / train_batch_size\n",
    "total_steps = max_train_steps or int(max_train_epochs * steps_per_epoch)\n",
    "lr_warmup_steps = int(total_steps * lr_warmup_ratio)\n",
    "\n",
    "print(f\"üìÅ Found {len(images)} images with {num_repeats} repeats\")\n",
    "print(f\"üìà {steps_per_epoch:.0f} steps per epoch, {total_steps} total steps\")\n",
    "\n",
    "# Download model\n",
    "print(\"\\nüîÑ Downloading model...\")\n",
    "model_file = os.path.join(root_dir, model_url.split('/')[-1])\n",
    "\n",
    "if not os.path.exists(model_file):\n",
    "    !aria2c \"{model_url}\" --console-log-level=warn -c -s 16 -x 16 -k 10M -d \"{root_dir}\" -o \"{os.path.basename(model_file)}\"\n",
    "\n",
    "if not os.path.exists(model_file):\n",
    "    raise ValueError(\"Failed to download model\")\n",
    "print(f\"‚úÖ Model ready: {model_file}\")\n",
    "\n",
    "# Network settings\n",
    "network_module = \"networks.lora\"\n",
    "network_args = None\n",
    "if lora_type.lower() == \"locon\":\n",
    "    network_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\"]\n",
    "\n",
    "# Optimizer settings for Prodigy/DAdaptation\n",
    "optimizer_args = None\n",
    "actual_unet_lr = unet_lr\n",
    "actual_text_encoder_lr = text_encoder_lr\n",
    "actual_lr_scheduler = lr_scheduler\n",
    "actual_network_alpha = network_alpha\n",
    "actual_optimizer = optimizer\n",
    "\n",
    "# Check if bitsandbytes is available for 8-bit optimizers\n",
    "if \"8bit\" in optimizer.lower() and not bitsandbytes_available:\n",
    "    print(f\"‚ö†Ô∏è {optimizer} requires bitsandbytes which is not available\")\n",
    "    print(\"   Falling back to regular AdamW optimizer\")\n",
    "    actual_optimizer = \"AdamW\"\n",
    "\n",
    "if optimizer.lower() == \"prodigy\" or \"dadapt\" in optimizer.lower():\n",
    "    actual_unet_lr = 1.0\n",
    "    actual_text_encoder_lr = 1.0\n",
    "    actual_lr_scheduler = \"constant_with_warmup\"\n",
    "    actual_network_alpha = network_dim\n",
    "    optimizer_args = [\"decouple=True\", \"weight_decay=0.01\", \"betas=[0.9,0.999]\"]\n",
    "    if optimizer.lower() == \"prodigy\":\n",
    "        optimizer_args.extend([\"d_coef=2\", \"use_bias_correction=True\", \"safeguard_warmup=True\"])\n",
    "\n",
    "lr_scheduler_num_cycles = lr_scheduler_number if lr_scheduler == \"cosine_with_restarts\" else 0\n",
    "lr_scheduler_power = lr_scheduler_number if lr_scheduler == \"polynomial\" else 0\n",
    "min_snr_gamma_value = 5.0 if min_snr_gamma else None\n",
    "\n",
    "# Create config\n",
    "print(\"\\nüìÑ Creating config files...\")\n",
    "config_dict = {\n",
    "    \"additional_network_arguments\": {\n",
    "        \"unet_lr\": actual_unet_lr,\n",
    "        \"text_encoder_lr\": actual_text_encoder_lr,\n",
    "        \"network_dim\": network_dim,\n",
    "        \"network_alpha\": actual_network_alpha,\n",
    "        \"network_module\": network_module,\n",
    "        \"network_args\": network_args,\n",
    "        \"network_train_unet_only\": True if actual_text_encoder_lr == 0 else None,\n",
    "    },\n",
    "    \"optimizer_arguments\": {\n",
    "        \"learning_rate\": actual_unet_lr,\n",
    "        \"lr_scheduler\": actual_lr_scheduler,\n",
    "        \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles if actual_lr_scheduler == \"cosine_with_restarts\" else None,\n",
    "        \"lr_scheduler_power\": lr_scheduler_power if actual_lr_scheduler == \"polynomial\" else None,\n",
    "        \"lr_warmup_steps\": lr_warmup_steps if actual_lr_scheduler != \"constant\" else None,\n",
    "        \"optimizer_type\": actual_optimizer,\n",
    "        \"optimizer_args\": optimizer_args,\n",
    "    },\n",
    "    \"training_arguments\": {\n",
    "        \"max_train_steps\": max_train_steps,\n",
    "        \"max_train_epochs\": max_train_epochs,\n",
    "        \"save_every_n_epochs\": save_every_n_epochs,\n",
    "        \"save_last_n_epochs\": keep_only_last_n_epochs,\n",
    "        \"train_batch_size\": train_batch_size,\n",
    "        \"clip_skip\": 2,\n",
    "        \"min_snr_gamma\": min_snr_gamma_value,\n",
    "        \"seed\": 42,\n",
    "        \"max_token_length\": 225,\n",
    "        \"xformers\": xformers_available,\n",
    "        \"lowram\": COLAB,\n",
    "        \"max_data_loader_n_workers\": 8,\n",
    "        \"persistent_data_loader_workers\": True,\n",
    "        \"save_precision\": \"fp16\",\n",
    "        \"mixed_precision\": \"fp16\",\n",
    "        \"output_dir\": output_folder,\n",
    "        \"logging_dir\": log_folder,\n",
    "        \"output_name\": project_name,\n",
    "        \"log_prefix\": project_name,\n",
    "    },\n",
    "    \"model_arguments\": {\n",
    "        \"pretrained_model_name_or_path\": model_file,\n",
    "        \"v2\": custom_model_is_based_on_sd2,\n",
    "        \"v_parameterization\": True if custom_model_is_based_on_sd2 else None,\n",
    "    },\n",
    "    \"saving_arguments\": {\n",
    "        \"save_model_as\": \"safetensors\",\n",
    "    },\n",
    "    \"dreambooth_arguments\": {\n",
    "        \"prior_loss_weight\": 1.0,\n",
    "    },\n",
    "    \"dataset_arguments\": {\n",
    "        \"cache_latents\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Remove None values\n",
    "for key in config_dict:\n",
    "    if isinstance(config_dict[key], dict):\n",
    "        config_dict[key] = {k: v for k, v in config_dict[key].items() if v is not None}\n",
    "\n",
    "with open(config_file, \"w\") as f:\n",
    "    f.write(toml.dumps(config_dict))\n",
    "print(f\"üìÑ Config saved to {config_file}\")\n",
    "\n",
    "# Create dataset config\n",
    "dataset_config_dict = {\n",
    "    \"general\": {\n",
    "        \"resolution\": resolution,\n",
    "        \"shuffle_caption\": shuffle_caption,\n",
    "        \"keep_tokens\": keep_tokens,\n",
    "        \"flip_aug\": flip_aug,\n",
    "        \"caption_extension\": caption_extension,\n",
    "        \"enable_bucket\": True,\n",
    "        \"bucket_reso_steps\": 64,\n",
    "        \"bucket_no_upscale\": False,\n",
    "        \"min_bucket_reso\": 320 if resolution > 640 else 256,\n",
    "        \"max_bucket_reso\": 1280 if resolution > 640 else 1024,\n",
    "    },\n",
    "    \"datasets\": [\n",
    "        {\n",
    "            \"subsets\": [\n",
    "                {\n",
    "                    \"num_repeats\": num_repeats,\n",
    "                    \"image_dir\": images_folder,\n",
    "                    \"class_tokens\": None if caption_extension else project_name\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Remove None values from general\n",
    "dataset_config_dict[\"general\"] = {k: v for k, v in dataset_config_dict[\"general\"].items() if v is not None}\n",
    "for subset in dataset_config_dict[\"datasets\"][0][\"subsets\"]:\n",
    "    for k in list(subset.keys()):\n",
    "        if subset[k] is None:\n",
    "            del subset[k]\n",
    "\n",
    "with open(dataset_config_file, \"w\") as f:\n",
    "    f.write(toml.dumps(dataset_config_dict))\n",
    "print(f\"üìÑ Dataset config saved to {dataset_config_file}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: Start Training\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3: Starting Training\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "# Set environment variables to suppress warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "cmd = [\n",
    "    sys.executable, \"-m\", \"accelerate.commands.launch\",\n",
    "    f\"--config_file={accelerate_config_file}\",\n",
    "    \"--num_cpu_threads_per_process=1\",\n",
    "    \"train_network.py\",\n",
    "    f\"--dataset_config={dataset_config_file}\",\n",
    "    f\"--config_file={config_file}\"\n",
    "]\n",
    "\n",
    "# Launch training with filtered output\n",
    "process = subprocess.Popen(\n",
    "    cmd,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    universal_newlines=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "skip_patterns = [\n",
    "    \"Unable to register cuDNN\",\n",
    "    \"Unable to register cuBLAS\",\n",
    "    \"computation placer already registered\",\n",
    "    \"compiled without GPU support\",\n",
    "    \"undefined symbol: cadam32bit\",\n",
    "    \"SyntaxWarning:\",\n",
    "    \"invalid escape sequence\",\n",
    "    '\"is not\" with \\'str\\' literal',\n",
    "    \"torchao.kernel.intmm\",\n",
    "    \"non-existent\",\n",
    "    \"CUDA_SETUP:\",\n",
    "    \"CUDA SETUP:\",\n",
    "    \"libcudart.so\",\n",
    "    \"libbitsandbytes\",\n",
    "]\n",
    "\n",
    "print(\"‚≠ê Training started - filtering warnings...\\n\")\n",
    "\n",
    "last_step_line = \"\"\n",
    "for line in process.stdout:\n",
    "    stripped = line.strip()\n",
    "    # Skip empty/trivial lines\n",
    "    if stripped in (\"\", \"False\", \"True\"):\n",
    "        continue\n",
    "    # Skip known non-critical warnings\n",
    "    if any(skip in line for skip in skip_patterns):\n",
    "        continue\n",
    "    # Deduplicate tqdm progress lines - only show the latest update per step\n",
    "    if \"steps:\" in line and \"it/s\" in line or \"s/it\" in line:\n",
    "        last_step_line = line\n",
    "        continue\n",
    "    # Flush the last progress line before printing a non-progress line\n",
    "    if last_step_line:\n",
    "        print(last_step_line, end='')\n",
    "        last_step_line = \"\"\n",
    "    print(line, end='')\n",
    "\n",
    "# Print any remaining progress line\n",
    "if last_step_line:\n",
    "    print(last_step_line, end='')\n",
    "\n",
    "process.wait()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "if process.returncode == 0:\n",
    "    print(\"‚úÖ Training completed successfully!\")\n",
    "    print(f\"üìÅ Your LoRA is saved in: {output_folder}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Training stopped with exit code {process.returncode}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56302632",
   "metadata": {},
   "source": [
    "## *Ô∏è‚É£ Extras\n",
    "\n",
    "Optional utilities for dataset management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ### üìÇ Unzip dataset\n",
    "#@markdown Upload a zip file and extract it to your dataset folder.\n",
    "zip_file = \"/content/drive/MyDrive/my_dataset.zip\" #@param {type:\"string\"}\n",
    "extract_to = \"/content/drive/MyDrive/Loras/my_lora/dataset\" #@param {type:\"string\"}\n",
    "\n",
    "import os, zipfile\n",
    "\n",
    "if 'google.colab' in str(get_ipython()) and not os.path.exists('/content/drive'):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "os.makedirs(extract_to, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_file, 'r') as f:\n",
    "    f.extractall(extract_to)\n",
    "print(\"‚úÖ Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c285c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ### üî¢ Count files in folders\n",
    "folder = \"/content/drive/MyDrive/Loras\" #@param {type:\"string\"}\n",
    "\n",
    "import os\n",
    "\n",
    "if 'google.colab' in str(get_ipython()) and not os.path.exists('/content/drive'):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    dirs[:] = [d for d in dirs if d not in ('_logs', 'output')]\n",
    "    images = len([f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    if images:\n",
    "        print(f\"üìÅ {root}: {images} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6331c3d",
   "metadata": {},
   "source": [
    "# üìà TensorBoard\n",
    "View training progress after running the trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir={log_folder}/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
